<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Browser Speaker Diarization Demo</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .speaker-1 { border-left: 4px solid #3b82f6; }
        .speaker-2 { border-left: 4px solid #ef4444; }
        .speaker-3 { border-left: 4px solid #10b981; }
        .speaker-unknown { border-left: 4px solid #9ca3af; }
    </style>
</head>
<body class="bg-gray-50 min-h-screen font-sans">
    <div class="max-w-3xl mx-auto p-6">
        <header class="mb-8 text-center">
            <h1 class="text-3xl font-bold text-gray-800">オフライン話者分離デモ (v2.2)</h1>
            <p class="text-gray-600 mt-2">トークナイザー・エラーを回避した安定版</p>
        </header>

        <div class="bg-white rounded-2xl shadow-sm p-6 mb-6">
            <div id="status-container" class="mb-6 p-4 rounded-xl transition-colors">
                <div class="flex items-center justify-between">
                    <div id="status" class="flex items-center space-x-2">
                        <span id="status-dot" class="relative inline-flex rounded-full h-3 w-3 bg-yellow-500"></span>
                        <span id="status-text" class="text-sm font-medium text-gray-700">Initializing...</span>
                    </div>
                    <div id="progress-bar-container" class="hidden w-1/2 bg-gray-200 rounded-full h-2">
                        <div id="progress-bar" class="bg-blue-600 h-2 rounded-full" style="width: 0%"></div>
                    </div>
                </div>
                <div id="error-details" class="hidden mt-4 text-xs text-red-600 font-mono bg-red-50 p-3 rounded-lg border border-red-100 whitespace-pre-wrap"></div>
            </div>
            
            <div class="flex space-x-2 mb-6">
                <button id="record-btn" disabled class="flex-1 px-6 py-4 bg-blue-600 text-white rounded-2xl font-bold hover:bg-blue-700 disabled:opacity-30 transition-all shadow-lg shadow-blue-200">
                    録音開始
                </button>
                <button id="stop-btn" disabled class="flex-1 px-6 py-4 bg-red-500 text-white rounded-2xl font-bold hover:bg-red-600 disabled:opacity-30 transition-all shadow-lg shadow-red-200">
                    停止して分析
                </button>
            </div>

            <div id="visualizer-container" class="w-full h-24 bg-gray-900 rounded-2xl overflow-hidden">
                <canvas id="visualizer" class="w-full h-full"></canvas>
            </div>
        </div>

        <div class="space-y-4">
            <div class="flex items-center justify-between">
                <h2 class="text-xl font-bold text-gray-800">分析結果</h2>
                <button id="clear-btn" class="text-xs text-gray-400 hover:text-gray-600 underline">クリア</button>
            </div>
            <div id="results" class="space-y-3 min-h-[200px] border-2 border-dashed border-gray-200 rounded-2xl flex flex-col items-center justify-center bg-white/50">
                <p id="placeholder-text" class="text-gray-400 italic text-sm text-center px-4">録音を開始してください。終了後、AIが話者を特定します。</p>
            </div>
        </div>
    </div>

    <script type="module">
        // pipelineではなく、低レイヤーのクラスをインポート
        import { AutoModel, AutoFeatureExtractor, env } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.0.2';

        env.allowLocalModels = false;
        env.allowRemoteModels = true;

        const recordBtn = document.getElementById('record-btn');
        const stopBtn = document.getElementById('stop-btn');
        const statusText = document.getElementById('status-text');
        const statusDot = document.getElementById('status-dot');
        const errorDetails = document.getElementById('error-details');
        const resultsContainer = document.getElementById('results');
        const progressBarContainer = document.getElementById('progress-bar-container');
        const progressBar = document.getElementById('progress-bar');
        const canvas = document.getElementById('visualizer');
        const canvasCtx = canvas.getContext('2d');

        let model;
        let processor;
        let mediaRecorder;
        let audioChunks = [];
        let audioContext;
        let analyser;
        let animationId;

        async function init() {
            try {
                statusText.innerText = 'AIモデルを読み込み中...';
                progressBarContainer.classList.remove('hidden');

                const modelId = 'Xenova/wav2vec2-base-superb-sid';

                // 1. 特徴抽出器をロード (tokenizerを読み込まない)
                processor = await AutoFeatureExtractor.from_pretrained(modelId);
                
                // 2. モデル本体をロード
                model = await AutoModel.from_pretrained(modelId, {
                    device: 'webgpu', // WebGPUが使えれば高速動作
                    progress_callback: (data) => {
                        if (data.status === 'progress') {
                            progressBar.style.width = `${data.progress}%`;
                            statusText.innerText = `ダウンロード中: ${Math.round(data.progress)}%`;
                        }
                    }
                });
                
                statusText.innerText = '準備完了';
                statusDot.className = 'relative inline-flex rounded-full h-3 w-3 bg-green-500';
                progressBarContainer.classList.add('hidden');
                recordBtn.disabled = false;
            } catch (err) {
                console.error("Initialization error:", err);
                statusText.innerText = 'ロード失敗';
                statusDot.className = 'relative inline-flex rounded-full h-3 w-3 bg-red-500';
                errorDetails.classList.remove('hidden');
                errorDetails.innerText = `エラー詳細: ${err.message}\n\nこのエラーは主にネットワーク遮断かブラウザのセキュリティ設定により発生します。`;
            }
        }

        recordBtn.onclick = async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                if (!audioContext) audioContext = new AudioContext({ sampleRate: 16000 });
                if (audioContext.state === 'suspended') await audioContext.resume();

                const source = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                source.connect(analyser);
                
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
                mediaRecorder.onstop = processAudio;
                mediaRecorder.start();

                recordBtn.disabled = true;
                stopBtn.disabled = false;
                statusText.innerText = 'マイク録音中...';
                drawVisualizer();
            } catch (err) {
                alert("マイク利用が許可されませんでした。");
            }
        };

        stopBtn.onclick = () => {
            mediaRecorder.stop();
            mediaRecorder.stream.getTracks().forEach(t => t.stop());
            recordBtn.disabled = false;
            stopBtn.disabled = true;
            statusText.innerText = 'AI分析を開始します...';
            cancelAnimationFrame(animationId);
        };

        async function processAudio() {
            try {
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                const arrayBuffer = await audioBlob.arrayBuffer();
                const decodedData = await audioContext.decodeAudioData(arrayBuffer);
                const rawData = decodedData.getChannelData(0);
                
                // 1.5秒ごとのスライス
                const windowSize = 16000 * 1.5;
                const segments = [];
                for (let i = 0; i < rawData.length; i += windowSize) {
                    const chunk = rawData.slice(i, i + windowSize);
                    const rms = Math.sqrt(chunk.reduce((a, b) => a + b * b, 0) / chunk.length);
                    if (rms > 0.012) {
                        segments.push({
                            data: chunk,
                            start: (i / 16000).toFixed(1),
                            end: (Math.min(i + windowSize, rawData.length) / 16000).toFixed(1)
                        });
                    }
                }

                if (segments.length === 0) {
                    statusText.innerText = '声が検出されませんでした';
                    return;
                }

                const results = [];
                const speakerEmbeddings = [];

                for (const seg of segments) {
                    // 1. 音声をテンソルに変換
                    const inputs = await processor(seg.data);
                    
                    // 2. 推論実行
                    const { last_hidden_state } = await model(inputs);
                    
                    // 3. 平均プーリングにより特徴ベクトル(Embedding)を生成
                    // last_hidden_state.data は Float32Array
                    const embedding = meanPool(last_hidden_state);
                    
                    let speakerId = assignSpeaker(embedding, speakerEmbeddings);
                    results.push({ ...seg, speakerId });
                }

                displayResults(results);
                statusText.innerText = '分析完了';
            } catch (e) {
                console.error(e);
                statusText.innerText = '分析中にエラーが発生しました';
            }
        }

        // テンソルの平均を取る簡易プーリング
        function meanPool(tensor) {
            const data = tensor.data;
            const dims = tensor.dims; // [batch, seq_len, hidden_size]
            const hiddenSize = dims[2];
            const seqLen = dims[1];
            
            const result = new Float32Array(hiddenSize).fill(0);
            for (let s = 0; s < seqLen; s++) {
                for (let h = 0; h < hiddenSize; h++) {
                    result[h] += data[s * hiddenSize + h];
                }
            }
            for (let h = 0; h < hiddenSize; h++) {
                result[h] /= seqLen;
            }
            return result;
        }

        function assignSpeaker(newEmb, existingEmbs) {
            const threshold = 0.85;
            let maxSim = -1;
            let bestIdx = -1;

            for (let i = 0; i < existingEmbs.length; i++) {
                const sim = cosineSimilarity(newEmb, existingEmbs[i].avg);
                if (sim > maxSim) {
                    maxSim = sim;
                    bestIdx = i;
                }
            }

            if (maxSim > threshold) {
                const s = existingEmbs[bestIdx];
                s.count++;
                for (let j = 0; j < newEmb.length; j++) {
                    s.avg[j] = (s.avg[j] * (s.count - 1) + newEmb[j]) / s.count;
                }
                return bestIdx + 1;
            } else {
                existingEmbs.push({ avg: new Float32Array(newEmb), count: 1 });
                return existingEmbs.length;
            }
        }

        function cosineSimilarity(a, b) {
            let dot = 0, mA = 0, mB = 0;
            for (let i = 0; i < a.length; i++) {
                dot += a[i] * b[i];
                mA += a[i] * a[i];
                mB += b[i] * b[i];
            }
            return dot / (Math.sqrt(mA) * Math.sqrt(mB));
        }

        function displayResults(results) {
            resultsContainer.innerHTML = '';
            resultsContainer.classList.remove('items-center', 'justify-center');
            results.forEach(res => {
                const div = document.createElement('div');
                div.className = `w-full p-4 bg-white rounded-xl shadow-sm border speaker-${res.speakerId <= 3 ? res.speakerId : 'unknown'}`;
                div.innerHTML = `
                    <div class="flex justify-between items-center">
                        <span class="font-bold text-gray-800 flex items-center">
                            <span class="w-2 h-2 rounded-full mr-2 bg-current opacity-70"></span>
                            話者 ${res.speakerId}
                        </span>
                        <span class="text-xs font-mono text-gray-400">${res.start}s - ${res.end}s</span>
                    </div>
                `;
                resultsContainer.appendChild(div);
            });
        }

        function drawVisualizer() {
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            canvas.width = canvas.offsetWidth;
            canvas.height = canvas.offsetHeight;
            const draw = () => {
                animationId = requestAnimationFrame(draw);
                analyser.getByteFrequencyData(dataArray);
                canvasCtx.fillStyle = '#111827';
                canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
                const barWidth = (canvas.width / bufferLength) * 2.5;
                let x = 0;
                for (let i = 0; i < bufferLength; i++) {
                    const barHeight = (dataArray[i] / 255) * canvas.height;
                    canvasCtx.fillStyle = `rgb(59, 130, 246)`;
                    canvasCtx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
                    x += barWidth + 1;
                }
            };
            draw();
        }

        document.getElementById('clear-btn').onclick = () => {
            resultsContainer.innerHTML = '<p class="text-gray-400 italic text-sm text-center px-4">録音を開始してください。終了後、AIが話者を特定します。</p>';
            resultsContainer.classList.add('items-center', 'justify-center');
        };

        init();
    </script>
</body>
</html>
